# -*- coding: utf-8 -*-
"""Alzheimer's Drug Screening.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18pwgOHIMiw2KzKy2GvlZHdAoiD0gWjx6
"""

pip install pandas

import pandas as pd

pip install chembl_webresource_client

from chembl_webresource_client.new_client import new_client

import requests

target_protein=new_client.target

target_protein_query=target_protein.search('Alzheimer disease')

#Building a data frame:
targets=pd.DataFrame(target_protein_query)

targets

# @title target_type

from matplotlib import pyplot as plt
import seaborn as sns
targets.groupby('target_type').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

from matplotlib import pyplot as plt
import seaborn as sns

# Create the plot
targets.groupby('target_type').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right']].set_visible(False)

# Save the plot with high DPI
plt.tight_layout()
plt.savefig('target_type_plot.png', dpi=1500, bbox_inches='tight')

# Optional: Show the plot (if you want to view it)
# plt.show()

selected_target_protein=targets.target_chembl_id[3]

selected_target_protein

activity_target_protein=new_client.activity

res=activity_target_protein.filter(target_chembl_id=selected_target_protein).filter(standard_type="IC50")

res

drugs_df=pd.DataFrame(res)

drugs_df

Drugs=drugs_df.to_csv("AD4.csv", index=False)

from google.colab import files

files.download("AD4.csv")

drugs_df= pd.read_csv("/content/Drugs.csv")

# Removal of missing values from data set:
df2=drugs_df[drugs_df.standard_value.notna()]
df2

#Selecting columns from df2 data frame
selection=['molecule_chembl_id', 'canonical_smiles', 'standard_value']
df3=df2[selection]
df3

#Discretization of bioactivities:
bioactivity_class=[]
for i in df2.standard_value:
  if float(i) >= 10000:
    bioactivity_class.append("inactive")
  elif float(i) <= 1000:
    bioactivity_class.append("active")
  else:
    bioactivity_class.append("intermediate")

bioactivity_class

#Building a data frame from bioactivity_class
bioactivity_class=pd.DataFrame(bioactivity_class)
bioactivity_class

#Combining bioactivity_class into df3 data frame
df3=pd.concat([df3, bioactivity_class], axis=1)
df3

#Generating csv file
df3.to_csv('preprocessed_data.csv', index=False)

#Evaluation of Lipinski properties of drugs

! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh
! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh
! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local
! conda install -c rdkit rdkit -y
import sys
sys.path.append('/usr/local/lib/python3.7/site-packages/')

df = pd.read_csv('/content/preprocessed_data.csv')
df

#Removing canonical_smiles column from above data frame
df_no_smiles = df.drop(columns='canonical_smiles')
df_no_smiles

smiles = []

for i in df.canonical_smiles.tolist():
  cpd = str(i).split('.')
  cpd_longest = max(cpd, key = len)
  smiles.append(cpd_longest)

smiles = pd.Series(smiles, name = 'canonical_smiles')

df_clean_smiles = pd.concat([df_no_smiles,smiles], axis=1)
df_clean_smiles

import numpy as np

!pip install rdkit

!pip install --upgrade numpy  # First, make sure NumPy is up-to-date
!pip install --upgrade --force-reinstall rdkit # Reinstall RDKit to compile with the updated NumPy.

from rdkit import Chem

from rdkit.Chem import Descriptors, Lipinski

#Evaluating Lipinski descriptors
def lipinski(smiles, verbose=False):

    moldata= []
    for elem in smiles:
        mol=Chem.MolFromSmiles(elem)
        moldata.append(mol)

    baseData= np.arange(1,1)
    i=0
    for mol in moldata:

        desc_MolWt = Descriptors.MolWt(mol)
        desc_MolLogP = Descriptors.MolLogP(mol)
        desc_NumHDonors = Lipinski.NumHDonors(mol)
        desc_NumHAcceptors = Lipinski.NumHAcceptors(mol)

        row = np.array([desc_MolWt,
                        desc_MolLogP,
                        desc_NumHDonors,
                        desc_NumHAcceptors])

        if(i==0):
            baseData=row
        else:
            baseData=np.vstack([baseData, row])
        i=i+1

    columnNames=["MW","LogP","NumHDonors","NumHAcceptors"]
    descriptors = pd.DataFrame(data=baseData,columns=columnNames)

    return descriptors

df_lipinski = lipinski(df_clean_smiles.canonical_smiles)
df_lipinski

df_combined = pd.concat([df,df_lipinski], axis=1)
df_combined

#Generating csv file
df_combined.to_csv('lipinski_file.csv', index=False)

df = pd.read_csv('/content/lipinski_file.csv')
df

#Normalization of standard_values
def norm_value(standard_value):
    norm = []
    for i in standard_value:
        if i > 100000000:
            i = 100000000
        norm.append(i)
        x = pd.Series(norm, name='standard_value_norm')
    return x

#Function call to normalize standard_values from df data frame
standard_value_norm = norm_value(df['standard_value'])
standard_value_norm

#Building a data frame from standard_value_norm
standard_value_norm_df=pd.DataFrame(standard_value_norm)
standard_value_norm_df

#Combining two data frames
dfa = pd.concat([df,standard_value_norm_df], axis=1)
dfa

#Designing function for calculating pIC50 values from standard_value
def pIC50(standard_value):
    pIC50_values = []
    for IC50_nmol in standard_value:
        IC50_mol = IC50_nmol * 1e-9
        pIC50_value = -np.log10(IC50_mol)
        pIC50_values.append(pIC50_value)
    return pIC50_values

pIC50

#Converting strings present in standard_value_norm_column to float (if any present)
float_standard_value_norm=dfa['standard_value_norm'].apply(float)
float_standard_value_norm

#Using pIC50 function on standard_value_norm
pIC50_values=pIC50(float_standard_value_norm)
pIC50_values

#Building a data frame from pIC50_values
df_pIC50=pd.DataFrame({'pIC50_values':pIC50_values})
df_pIC50

#Combining two data frames
dfb=pd.concat([dfa,df_pIC50],axis=1)
dfb

#Describing data
dfb.standard_value_norm.describe()

#Omitting the intermediate results from bioactivity_class column from df2 data frame
final_df = dfb[dfb['bioactivity_class'] != 'intermediate']
final_df

final_df.to_csv('final_output_file.csv', index=False)

final_output=pd.read_csv("/content/final_output_file.csv")
final_output

import matplotlib.pyplot as plt
import seaborn as sns

#Bar chart(Frequency of Bioactivity Classes)
bioactivity_class = final_output['bioactivity_class']
class_counts=final_output['bioactivity_class'].value_counts()
class_counts

fig,ax=plt.subplots()
ax.bar(class_counts.index,class_counts.values,color=['green','orange'])
ax.set_xlabel('Bioactivity_class')
ax.set_ylabel('Frequency of bioactivity classes')
ax.set_title('Frequency of bioactivity classes')
# Save the plot with high DPI
plt.tight_layout()
plt.savefig('frequency of bioactivity class.png', dpi=1500, bbox_inches='tight')
plt.show()

#Scatter plot(Relation between Molecular Weight and LogP)
g=sns.scatterplot(x="MW",y="LogP",data=final_output,hue="bioactivity_class")
# Save the plot with high DPI
plt.tight_layout()
plt.savefig('MW vs LogP.png', dpi=1500, bbox_inches='tight')
plt.show()

#Box plot(Relation between Bioactivity class and pIC50_values)
g=sns.boxplot(x="bioactivity_class",y="pIC50_values",data=final_output)
g.set_title("Relation between bioactivity class and pIC50 values",y=1.03)
# Save the plot with high DPI
plt.tight_layout()
plt.savefig('BAC vs pIC50.png', dpi=1500, bbox_inches='tight')
plt.show()

import pandas as pd
final_output = pd.read_csv("/content/final_output_file.csv")
final_output

df=final_output
df

#Mann Whitney test on ctive and inactive bioactivity classes with reference to standard_value
selected_columns=df[['standard_value','bioactivity_class']]

active_group = df[df['bioactivity_class'] == 'active']
inactive_group = df[df['bioactivity_class'] == 'inactive']

active_standard_values = active_group['standard_value']
inactive_standard_values = inactive_group['standard_value']

active_standard_values
inactive_standard_values

from scipy.stats import mannwhitneyu

# Assuming active_standard_values and inactive_standard_values are already defined lists/arrays
test_statistic, p_value = mannwhitneyu(active_standard_values, inactive_standard_values, alternative='two-sided')

print("Mann-Whitney U statistic:", test_statistic)
print("p-value:", p_value)

#Mann Whitney test function:
def mann_whitney_test(active_standard_values, inactive_standard_values):
    U=[]
    p=[]
    np.random.seed(1)
    Î±=0.05
    combined_data = sorted(active_standard_values + inactive_standard_values)

    ranks = [sorted(combined_data).index(val) + 1 for val in combined_data]

    ranks_active = [ranks[i] for i in range(len(active_standard_values))]
    ranks_inactive = [ranks[i] for i in range(len(active_standard_values), len(combined_data))]

    U_active = sum(ranks_active)
    U_inactive = sum(ranks_inactive)

    U = min(U_active, U_inactive)

    n1 = len(active_standard_values)
    n2 = len(inactive_standard_values)


    expected_U = n1 * n2 / 2


    variance_U = (n1 * n2 * (n1 + n2 + 1)) / 12


    z_score = (U - expected_U) / sqrt(variance_U)


    p_value = 2 * (1 - abs(z_score))

    return U, p_value

results=print("Test Statistic (U):", test_statistic, "P-value:", p_value)

#Mann Whitney test on active and inactive bioactivity classes with reference to molecular weight
selected_columns=df[['MW','bioactivity_class']]

active_group = df[df['bioactivity_class'] == 'active']
inactive_group = df[df['bioactivity_class'] == 'inactive']

active_MW = active_group['MW']
inactive_MW = inactive_group['MW']

active_MW
inactive_MW

test_statistic, p_value = mannwhitneyu(active_MW, inactive_MW, alternative='two-sided')

print("Mann-Whitney U statistic:", test_statistic)
print("p-value:", p_value)

#Mann Whitney test on active and inactive bioactivity classes with reference to LogP
selected_columns=df[['LogP','bioactivity_class']]

active_group = df[df['bioactivity_class'] == 'active']
inactive_group = df[df['bioactivity_class'] == 'inactive']

active_LogP = active_group['LogP']
inactive_LogP = inactive_group['LogP']

active_LogP
inactive_LogP

test_statistic, p_value = mannwhitneyu(active_LogP, inactive_LogP, alternative='two-sided')

print("Mann-Whitney U statistic:", test_statistic)
print("p-value:", p_value)

#Mann Whitney test on active and inactive bioactivity classes with reference to NumHDonors
selected_columns=df[['NumHDonors','bioactivity_class']]

active_group = df[df['bioactivity_class'] == 'active']
inactive_group = df[df['bioactivity_class'] == 'inactive']

active_NumHDonors = active_group['NumHDonors']
inactive_NumHDonors = inactive_group['NumHDonors']

active_NumHDonors
inactive_NumHDonors

test_statistic, p_value = mannwhitneyu(active_NumHDonors, inactive_NumHDonors, alternative='two-sided')

print("Mann-Whitney U statistic:", test_statistic)
print("p-value:", p_value)

#Mann Whitney test on active and inactive bioactivity classes with reference to NumHAcceptors
selected_columns=df[['NumHAcceptors','bioactivity_class']]

active_NumHAcceptors = active_group['NumHAcceptors']
inactive_NumHAcceptors = inactive_group['NumHAcceptors']

active_NumHAcceptors
inactive_NumHAcceptors

test_statistic, p_value = mannwhitneyu(active_NumHAcceptors, inactive_NumHAcceptors, alternative='two-sided')

print("Mann-Whitney U statistic:", test_statistic)
print("p-value:", p_value)

#Mann Whitney test on active and inacive bioactivity classes with reference to standard_value_norm
selected_columns=df[['standard_value_norm','bioactivity_class']]

active_norm_value = active_group['standard_value_norm']
inactive_norm_value = inactive_group['standard_value_norm']

active_norm_value
inactive_norm_value

test_statistic, p_value = mannwhitneyu(active_norm_value, inactive_norm_value, alternative='two-sided')

print("Mann-Whitney U statistic:", test_statistic)
print("p-value:", p_value)

#Mann Whitney test on active and inactive bioactivity classes with reference to pIC50_values
selected_columns=df[['pIC50_values','bioactivity_class']]

active_pIC50_values = active_group['pIC50_values']
inactive_pIC50_values = inactive_group['pIC50_values']

active_pIC50_values
inactive_pIC50_values

test_statistic, p_value = mannwhitneyu(active_norm_value, inactive_norm_value, alternative='two-sided')

print("Mann-Whitney U statistic:", test_statistic)
print("p-value:", p_value)

import matplotlib.pyplot as plt
import seaborn as sns

#Generating a box plot (Relation between bioactivity class and Molecular Weight)
g=sns.boxplot(x="bioactivity_class",y="MW",data=final_output)
g.set_title("bioactivity class and molecular weight",y=1.03)
plt.savefig("bioactivity_class_and_molecular_weight.jpg",dpi=1500)

#Generating a box plot (Relation between bioactivity class and LogP)
g=sns.boxplot(x="bioactivity_class",y="LogP",data=final_output)
g.set_title("logp bioactivity class",y=1.03)
plt.savefig("logp bioactivity class.jpg",dpi=1500)

#Generating a box plot (Relation between bioactivity class and NumHDonors)
g=sns.boxplot(x="bioactivity_class",y="NumHDonors",data=final_output)
g.set_title("bioactivity class and NumHDonors",y=1.03)
plt.savefig("bioactivity_class_and_NumHDonors.jpg",dpi=1500)

#Generating a box plot (Relation between bioactivity class and NumHAcceptors)
g=sns.boxplot(x="bioactivity_class",y="NumHAcceptors",data=final_output)
g.set_title("bioactivity class and NumHAcceptors",y=1.03)
plt.savefig("bioactivity_class_and_NumHAcceptors.jpg",dpi=1500)

#Paddle installation
! wget https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip
! wget https://github.com/dataprofessor/bioinformatics/raw/master/padel.sh

! unzip padel.zip

import pandas as pd

final_output=pd.read_csv("/content/final_output_file.csv")

final_output

df=final_output
df

selection = ['canonical_smiles','molecule_chembl_id']
df_selection = df[selection]
df_selection.to_csv('molecule.smi', sep='\t', index=False, header=False)

! cat molecule.smi | head -5
! cat molecule.smi | 'wc -1'

! bash padel.sh

df2=pd.read_csv("/content/descriptors_output.csv")
df2

#Removing Chembl_id (Name) from "descriptors_output.csv"
df3 = df2.drop('Name', axis=1)
df3

#Selecting columns from df data frame generated from "final_output.csv" file
selected_columns = df[['standard_value','pIC50_values']]
selected_columns

df4 = pd.DataFrame(selected_columns)
df4

#Combining df3 and df4 data frames:
descriptors = pd.concat([df3, df4], axis=1)
descriptors

#Creating descriptors_final_file.csv
descriptors_final_file=descriptors.to_csv("descriptors_final_file.csv", index=False)

import pandas as pd

import seaborn as sns

from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestRegressor

descriptors_final_file=pd.read_csv("/content/descriptors_final_file.csv")
descriptors_final_file

df=descriptors_final_file
df

X = df.drop('pIC50_values', axis=1)
X

Y = df.pIC50_values
Y

X.shape
Y.shape

from sklearn.feature_selection import VarianceThreshold
selection = VarianceThreshold(threshold=(.01 * (1 - .01)))
X = selection.fit_transform(X)

X.shape

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)

X_train.shape, Y_train.shape

X_test.shape, Y_test.shape

model = RandomForestRegressor(n_estimators=100)
model.fit(X_train, Y_train)
r2 = model.score(X_test, Y_test)
r2

Y_pred = model.predict(X_test)

import seaborn as sns
import matplotlib.pyplot as plt

sns.set(color_codes=True)
sns.set_style("white")
ax = sns.regplot(x=Y_test, y=Y_pred, scatter_kws={'alpha': 0.4})
ax.set_xlabel('Experimental pIC50', fontsize='large', fontweight='bold')
ax.set_ylabel('Predicted pIC50', fontsize='large', fontweight='bold')
ax.set_xlim(0, 12)
ax.set_ylim(0, 12)
ax.figure.set_size_inches(5, 5)
# Save the plot with high DPI
plt.tight_layout()
plt.savefig('pIC50.png', dpi=1500, bbox_inches='tight')
plt.show()

import numpy as np
from sklearn.model_selection import cross_val_predict
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt

kf = KFold(n_splits=5, shuffle=True, random_state=42)
Y_pred_cv = cross_val_predict(model, X, Y, cv=kf)

plt.scatter(Y, Y_pred_cv)
plt.xlabel("True Values")
plt.ylabel("Predictions")
plt.title("True vs Predicted Values (Cross-Validation)")
plt.savefig('cross_validation.jpg', dpi=1500)

kf = KFold(n_splits=5, shuffle=True, random_state=42)

from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(model, X, Y, cv=kf, scoring='neg_root_mean_squared_error')
cv_rmse_scores = -cv_scores
print("Cross-validation RMSE Scores:", cv_rmse_scores)

print("Mean CV RMSE Score:", np.mean(cv_rmse_scores))
print("Standard Deviation of CV RMSE Scores:", np.std(cv_rmse_scores))

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error
from scipy.stats import randint
import numpy as np

# Example: X (features), y (target)
# Split your data first if you haven't already
# from sklearn.model_selection import train_test_split
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the model
rf = RandomForestRegressor(random_state=42)

# Define parameter grid
param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': [None, 10, 20, 30, 50],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}

# Setup RandomizedSearchCV
random_search = RandomizedSearchCV(
    rf,
    param_distributions=param_dist,
    n_iter=50,  # Number of parameter settings to sample
    scoring='neg_root_mean_squared_error',  # RMSE
    cv=5,  # 5-fold cross-validation
    verbose=2,
    random_state=42,
    n_jobs=-1
)

# Fit the search
random_search.fit(X, Y)

# Best model
best_model = random_search.best_estimator_

print("Best Parameters:", random_search.best_params_)

# Evaluate the best model
cv_scores = cross_val_score(best_model, X, Y, scoring='neg_root_mean_squared_error', cv=5)
cv_rmse_scores = -cv_scores  # Make them positive
print("Mean CV RMSE Score:", np.mean(cv_rmse_scores))
print("Standard Deviation of CV RMSE Scores:", np.std(cv_rmse_scores))

from sklearn.linear_model import LinearRegression  # Import LinearRegression
from sklearn.metrics import roc_curve, roc_auc_score # Import roc_curve and roc_auc_score

model = LinearRegression()  # Create a LinearRegression model
model.fit(X_train, Y_train)  # Train the model

# Predict values instead of probabilities
Y_pred = model.predict(X_test)

# For regression tasks, we typically use other metrics like R-squared, MSE, etc.
# To create an ROC curve, you'll need to adapt your approach for regression.
# One option is to use predicted values as a proxy for probability (with appropriate thresholds)
# However, this might not be ideal for all regression problems.

# Assuming 'Y_test' contains your ground truth values (continuous target variable)
# and 'Y_pred' contains your predicted values:

# Define thresholds based on your data or problem (consider quantiles or business rules)
thresholds = [np.quantile(Y_pred, q) for q in np.linspace(0, 1, 101)]

# Calculate TPR and FPR for each threshold
fpr, tpr, _ = roc_curve(Y_test > np.median(Y_test), Y_pred, pos_label=1, drop_intermediate=False)

# Calculate AUC
roc_auc = roc_auc_score(Y_test > np.median(Y_test), Y_pred)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.savefig('roc _curve.jpg', dpi=1500)

r2 = model.score(X_test, Y_test)
r2

!pip install pickle-mixin
!pip install pickle-mixin
import pickle
pickle.dump(model, open('model1.pkl', 'wb'))
!pip install joblib
import joblib
model_file = "model.pkl"
model = joblib.load(model_file)
model = joblib.load(model_file)